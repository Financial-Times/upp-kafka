---
apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: {{ .Values.service.name }}-rest-proxy
  labels:
    chart: "{{ .Chart.Name | trunc 63 }}"
    chartVersion: "{{ .Chart.Version | trunc 63 }}"
    visualize: "true"
    app: {{ .Values.service.name }}-rest-proxy
spec:
  replicas: 1
  selector:
    matchLabels:
      app: {{ .Values.service.name }}-rest-proxy
  template:
    metadata:
      labels:
        app: {{ .Values.service.name }}-rest-proxy
        visualize: "true"
    spec:
      tolerations:
      # Making sure that Kafka-proxy will be scheduled on dedicated nodes for kafka. These nodes are tainted by the provisioner.
      - key: "dedicated"
        operator: "Equal"
        value: "kafka"
        effect: "NoSchedule"
      affinity:
        nodeAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            nodeSelectorTerms:
            - matchExpressions:
              - key: kube-aws.coreos.com/role
                operator: In
                values:
                - kafka-worker
      containers:
      - name: kafka-proxy
        image: {{ .Values.images.kafkaProxy }}
        imagePullPolicy: {{ .Values.image.pullPolicy }}
        env:
        - name: RP_FETCH_MESSAGE_MAX_BYTES
          value: "16777216"
        - name: RP_CONSUMER_REQUEST_MAX_BYTES
          value: "17825792"
        - name: RP_ZOOKEEPER_CONNECT
          value: "{{.Values.service.name}}-zookeeper:{{ .Values.ports.zookeeper }}"
        - name: RP_MAX_REQUEST_SIZE
          value: "17825792"
        ports:
        - containerPort: {{ .Values.ports.kafkaProxy }}
        livenessProbe:
          initialDelaySeconds: 90
          tcpSocket:
            port: {{ .Values.ports.kafkaProxy }}
        resources:
{{ toYaml .Values.kafkaProxyResources | indent 12 }}
